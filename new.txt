import numpy as np
import matplotlib.pyplot as plt
data = np.array([
    [1, 1],
    [1.5, 2],
    [3, 4],
    [5, 7],
    [3.5, 5],
    [4.5, 5],
    [3.5, 4]
])
centroids = np.array([data[0], data[3]])

def euclidean_distance(a, b):
    return np.sqrt(np.sum((a - b) ** 2))

def kmeans(data, centroids, max_iters=100):
    for _ in range(max_iters):
        clusters = [[] for _ in centroids]
        for point in data:
            distances = [euclidean_distance(point, centroid) for centroid in centroids]
            clusters[np.argmin(distances)].append(point)
        new_centroids = np.array([np.mean(cluster, axis=0) if cluster else centroid 
                                  for cluster, centroid in zip(clusters, centroids)])
        if np.all(centroids == new_centroids):
            break
        centroids = new_centroids
    return clusters, centroids
clusters, centroids = kmeans(data, centroids)
colors = ['r', 'b']
plt.figure(figsize=(8, 6))
for i, cluster in enumerate(clusters):
    cluster = np.array(cluster)
    plt.scatter(cluster[:, 0], cluster[:, 1], color=colors[i])
    plt.scatter(*centroids[i], color=colors[i], marker='x', s=100, linewidths=3)   
plt.xlabel('var1')
plt.ylabel('var2')
plt.title('K-means Clustering with Circular Boundaries')
plt.show()

-----------------------------------------------------------------

dataset = [
    {"Sky": "Sunny", "AirTemp": "Warm", "Humidity": "Normal", "Wind": "Strong", "Water": "Warm", "Forecast": "Same", "EnjoySport": "Yes"},
    {"Sky": "Sunny", "AirTemp": "Warm", "Humidity": "High", "Wind": "Strong", "Water": "Warm", "Forecast": "Same", "EnjoySport": "Yes"},
    {"Sky": "Rainy", "AirTemp": "Cold", "Humidity": "High", "Wind": "Strong", "Water": "Warm", "Forecast": "Change", "EnjoySport": "No"},
    {"Sky": "Sunny", "AirTemp": "Warm", "Humidity": "High", "Wind": "Strong", "Water": "Cool", "Forecast": "Change", "EnjoySport": "Yes"},
]
initial_positive_example = next(example for example in dataset if example["EnjoySport"] == "Yes")
print(initial_positive_example)
hypothesis = {key: value for key, value in initial_positive_example.items() if key != "EnjoySport"}
print(hypothesis)
for example in dataset:
    if example["EnjoySport"] == "Yes":
        for attribute, value in hypothesis.items():
            print(example[attribute],"\t",value)
            if example[attribute] != value:
                hypothesis[attribute] = "?"
print("Maximally Specific Hypothesis:", hypothesis)

-----------------------------------------------------------------------------------
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.mixture import GaussianMixture
iris=datasets.load_iris()
X=iris.data[:,:2]
d=pd.DataFrame(X,columns=['Feature1','Feature2'])
plt.figure(figsize=(8,6))
plt.scatter(d['Feature1'],d['Feature2'],color="gray",label="data points")
gmm=GaussianMixture(n_components=3,random_state=42,max_iter=100)
gmm.fit(d)
labels=gmm.predict(d)
d['labels']=labels
# print(d)
d0=d[d['labels']==0]
print(d0)
d1=d[d['labels']==1]
d2=d[d['labels']==2]
plt.scatter(d0['Feature1'],d0['Feature2'],color="red",label="Cluster 1")
plt.scatter(d1['Feature1'],d1['Feature2'],color="yellow",label="Cluster 2")
plt.scatter(d2['Feature1'],d2['Feature2'],color="green",label="Cluster 3")
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.show()

---------------------------------------------------------------------------------------------------
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
data = {
    'Day': ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14'],
    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],
    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],
    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],
    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong'],
    'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']
}
df = pd.DataFrame(data)
df = df.drop(columns=['Day'])
le = LabelEncoder()
for column in df.columns:
    df[column] = le.fit_transform(df[column])

X = df.drop(columns=['PlayTennis'])
y = df['PlayTennis']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
clf = DecisionTreeClassifier()
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

-------------------------------------------------------------------------------------------
import numpy as np
import matplotlib.pyplot as plt
X = np.array([1, 5, 1.5, 8, 1, 9, 7, 8.7, 2.3, 5.5, 7.7, 6.1])
Y = np.array([2, 8, 1.8, 8, 0.6, 11, 10, 9.4, 4, 3, 8.8, 7.5])
labels = np.array([-1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1])
data = list(zip(X, Y, labels))
w = np.array([0.0, 0.0])
b = 0.0
learning_rate = 0.001
iterations = 1000
lambda_param = 0.01  # Regularization parameter
for _ in range(iterations):
    for x_i, y_i, label in data:
        x = np.array([x_i, y_i])
        if label * (np.dot(w, x) + b) < 1:
            w += learning_rate * (label * x - 2 * lambda_param * w)
            b += learning_rate * label
        else:
            w += learning_rate * (-2 * lambda_param * w)
plt.scatter(X[labels == -1], Y[labels == -1], color='red', marker='o', label='Class -1')
plt.scatter(X[labels == 1], Y[labels == 1], color='blue', marker='x', label='Class 1')
slope = -w[0] / w[1]
intercept = -b / w[1]
x_values = np.linspace(min(X)-1, max(X)+1, 100)
y_optimal = slope * x_values + intercept
plt.plot(x_values, y_optimal, 'k-', label='Optimal Hyperplane')
margin = 1 / np.sqrt(np.sum(w**2))
y_margin_positive = slope * x_values + intercept + margin
y_margin_negative = slope * x_values + intercept - margin
plt.plot(x_values, y_margin_positive, 'g--', label='Positive Margin')
plt.plot(x_values, y_margin_negative, 'g--', label='Negative Margin')
plt.xlabel("X")
plt.ylabel("Y")
plt.legend()
plt.title("SVM with Optimal and Marginal Hyperplanes")
plt.show()
------------------------------------------------------------------------------------
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from collections import Counter
data = {
    'Height': [158, 158, 160, 160, 163, 163, 160, 163, 165, 165, 168, 168, 168, 170, 170, 170],
    'Weight': [58, 59, 59, 20, 60, 61, 64, 54, 61, 62, 62, 63, 66, 63, 64, 58],
    'TShirtSize': ['M', 'M', 'M', 'M', 'M', 'M', 'L', 'M', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L']}
df = pd.DataFrame(data)
tshirt_size_mapping = {'M': 0, 'L': 1}
df['TShirtSize'] = df['TShirtSize'].map(tshirt_size_mapping)
X = df[['Height', 'Weight']].values  # Features: Height and Weight
y = df['TShirtSize'].values  # Target: T-shirt Size (encoded)
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]
def euclidean_distance(x1, x2):
    return np.sqrt(np.sum((x1 - x2) ** 2))
def knn_predict(X_train, y_train, X_test, k=3):
    predictions = []
    for test_point in X_test:
        distances = []
        for idx, train_point in enumerate(X_train):
            distance = euclidean_distance(test_point, train_point)
            distances.append((distance, y_train[idx]))
        distances.sort(key=lambda x: x[0])
        k_nearest_neighbors = distances[:k]
        labels = [neighbor[1] for neighbor in k_nearest_neighbors]
        majority_label = Counter(labels).most_common(1)[0][0]
        predictions.append(majority_label)   
    return np.array(predictions)
new_customer = np.array([[167, 61]])  # New customer data
predicted_size = knn_predict(X_train, y_train, new_customer, k=3)
reverse_mapping = {0: 'M', 1: 'L'}
predicted_size_label = reverse_mapping[predicted_size[0]]
print("Predicted T-shirt size:", predicted_size_label)
y_pred = knn_predict(X_test, y_test, X_test, k=3)
accuracy = np.sum(y_pred == y_test) / len(y_test)
print("Model Accuracy:", accuracy)